// scripts/index-documents.ts
//
// Pokreni sa: npx tsx scripts/index-documents.ts
//
// Å ta radi:
// 1. Crawluje ELAB sajtove
// 2. SeÄe tekst na chunkove
// 3. GeneriÅ¡e Ollama embeddings za svaki chunk
// 4. Ubacuje sve u ChromaDB

import { WebCrawler } from '../src/lib/crawler'
import { TextChunker } from '../src/lib/text-chunker'
import { getVectorDB, VectorDocument } from '../src/lib/vector-db'
import { randomUUID } from 'crypto'

const START_URLS = [
  'https://elab.fon.bg.ac.rs',
  'https://bc.elab.fon.bg.ac.rs',
  'https://ebt.rs',
]

const CRAWLER_CONFIG = {
  maxDepth: 2,
  maxPages: 100,
  timeout: 15000,
}

const CHUNKER_CONFIG = {
  chunkSize: 512,
  chunkOverlap: 50,
}

async function main() {
  console.log('ğŸš€ ELAB AI Indexing Pipeline\n')

  // â”€â”€â”€ Korak 1: Crawlovanje â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  console.log('â•â•â• KORAK 1: Crawlovanje â•â•â•')
  const crawler = new WebCrawler(CRAWLER_CONFIG)
  const documents = await crawler.crawlMultiple(START_URLS)

  console.log('\nğŸ“Š Crawler statistika:')
  console.log(crawler.getStats())

  if (documents.length === 0) {
    console.error('âŒ Crawler nije pronaÅ¡ao nijedan dokument. Proveri mreÅ¾u i URL-ove.')
    process.exit(1)
  }

  // â”€â”€â”€ Korak 2: Chunking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  console.log('\nâ•â•â• KORAK 2: Chunking teksta â•â•â•')
  const chunker = new TextChunker(CHUNKER_CONFIG)
  const vectorDocuments: VectorDocument[] = []

  for (const doc of documents) {
    const chunks = chunker.createChunks(doc.content)

    for (const chunk of chunks) {
      vectorDocuments.push({
        id: randomUUID(),
        content: chunk.content,
        metadata: {
          url: doc.url,
          title: doc.title,
          sourceType: doc.metadata.sourceType,
          chunkIndex: chunk.index ?? 0,
          crawledAt: doc.metadata.crawledAt.toISOString(),
        },
      })
    }
  }

  console.log(`âœ… Kreirano ${vectorDocuments.length} chunkova od ${documents.length} stranica`)

  if (vectorDocuments.length === 0) {
    console.error('âŒ Nema chunkova za indexiranje.')
    process.exit(1)
  }

  // â”€â”€â”€ Korak 3: Inicijalizacija ChromaDB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  console.log('\nâ•â•â• KORAK 3: ÄŒiÅ¡Ä‡enje stare kolekcije â•â•â•')
  const db = await getVectorDB()

  // BriÅ¡i stare podatke kako bi izbegli meÅ¡anje starih TF-IDF
  // i novih Ollama embeddinga (nekompatibilne dimenzije)
  await db.clear()
  console.log('âœ… Stara kolekcija obrisana')

  // â”€â”€â”€ Korak 4: Embeddings + Indexiranje â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Ollama embedding je spor za veliki broj chunkova pa radimo u batchevima
  // kako bismo videli progress i izbegli timeout
  console.log('\nâ•â•â• KORAK 4: Generisanje embeddings i indexiranje â•â•â•')
  console.log('âš ï¸  Ovo moÅ¾e potrajati â€” Ollama generiÅ¡e embedding za svaki chunk\n')

  const BATCH_SIZE = 10
  let indexed = 0

  for (let i = 0; i < vectorDocuments.length; i += BATCH_SIZE) {
    const batch = vectorDocuments.slice(i, i + BATCH_SIZE)
    
    try {
      await db.addDocuments(batch)
      indexed += batch.length
      console.log(`ğŸ“¥ Indexirano: ${indexed}/${vectorDocuments.length} chunkova`)
    } catch (error: any) {
      console.error(`âŒ GreÅ¡ka pri indexiranju batch-a ${i}â€“${i + BATCH_SIZE}:`, error.message)
      // Nastavi sa sledeÄ‡im batch-em umesto da staneÅ¡
    }
  }

  // â”€â”€â”€ Korak 5: Verifikacija â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  console.log('\nâ•â•â• KORAK 5: Verifikacija â•â•â•')
  const stats = await db.getStats()
  console.log('ğŸ“Š ChromaDB statistika:', stats)

  // Brzi test pretrage
  console.log('\nğŸ” Test pretrage: "Ko je Zorica BogdanoviÄ‡?"')
  const testResults = await db.search('Ko je Zorica BogdanoviÄ‡?', { limit: 3 })
  
  if (testResults.length === 0) {
    console.warn('âš ï¸  Pretraga nije pronaÅ¡la rezultate â€” moÅ¾da crawlani sadrÅ¾aj ne sadrÅ¾i tu informaciju')
  } else {
    console.log(`âœ… PronaÄ‘eno ${testResults.length} rezultata:`)
    for (const result of testResults) {
      console.log(`  - [${Math.round(result.relevanceScore * 100)}%] ${result.metadata.title}`)
      console.log(`    ${result.content.slice(0, 100)}...`)
    }
  }

  console.log('\nâœ… Indexiranje zavrÅ¡eno!')
  process.exit(0)
}

main().catch(error => {
  console.error('ğŸ’¥ Fatalna greÅ¡ka:', error)
  process.exit(1)
})